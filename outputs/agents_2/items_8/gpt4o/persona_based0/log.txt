INFO:root:Generating outputs for 2 agents and 8 items with a uniform distribution using model gpt4o with temperature 0.7 and prompt type persona_based0...
INFO:root:Model first=ChatPromptTemplate(input_variables=['valuation'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['valuation'], input_types={}, partial_variables={}, template='{valuation}'), additional_kwargs={})]) middle=[ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x16c408220>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x16c4113d0>, root_client=<openai.OpenAI object at 0x16c1fe040>, root_async_client=<openai.AsyncOpenAI object at 0x16c408280>, model_name='gpt-4o-2024-08-06', model_kwargs={}, openai_api_key=SecretStr('**********'))] last=StrOutputParser() initialized
INFO:root:Starting output 486...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 486 generated
INFO:root:Starting output 487...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 487 generated
INFO:root:Starting output 488...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 488 generated
INFO:root:Starting output 489...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 489 generated
INFO:root:Starting output 490...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 490 generated
INFO:root:Starting output 491...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 491 generated
INFO:root:Starting output 492...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 492 generated
INFO:root:Starting output 493...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 493 generated
INFO:root:Starting output 494...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 494 generated
INFO:root:Starting output 495...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 495 generated
INFO:root:Starting output 496...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 496 generated
INFO:root:Starting output 497...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 497 generated
INFO:root:Starting output 498...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 498 generated
INFO:root:Starting output 499...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 499 generated
INFO:root:Starting output 500...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 500 generated
INFO:root:Outputs generated for 2 agents and 8 items with a uniform distribution using model first=ChatPromptTemplate(input_variables=['valuation'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['valuation'], input_types={}, partial_variables={}, template='{valuation}'), additional_kwargs={})]) middle=[ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x16c408220>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x16c4113d0>, root_client=<openai.OpenAI object at 0x16c1fe040>, root_async_client=<openai.AsyncOpenAI object at 0x16c408280>, model_name='gpt-4o-2024-08-06', model_kwargs={}, openai_api_key=SecretStr('**********'))] last=StrOutputParser() with temperature 0.7 and prompt type persona_based0...
