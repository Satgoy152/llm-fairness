INFO:root:Generating outputs for 3 agents and 7 items with a uniform distribution using model gpt4o with temperature 0.7 and prompt type persona_based1...
INFO:root:Model first=ChatPromptTemplate(input_variables=['valuation'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['valuation'], input_types={}, partial_variables={}, template='{valuation}'), additional_kwargs={})]) middle=[ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x15ce07640>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x15ce117f0>, root_client=<openai.OpenAI object at 0x15cdfd460>, root_async_client=<openai.AsyncOpenAI object at 0x15ce076a0>, model_name='gpt-4o-2024-08-06', model_kwargs={}, openai_api_key=SecretStr('**********'))] last=StrOutputParser() initialized
INFO:root:Starting output 137...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 137 generated
INFO:root:Starting output 138...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 138 generated
INFO:root:Starting output 139...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 139 generated
INFO:root:Starting output 140...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 140 generated
INFO:root:Starting output 141...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 141 generated
INFO:root:Starting output 142...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 142 generated
INFO:root:Starting output 143...
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:root:Output 143 generated
INFO:root:Starting output 144...
